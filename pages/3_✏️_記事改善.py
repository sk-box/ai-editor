"""
è¨˜äº‹æ”¹å–„ãƒšãƒ¼ã‚¸ - ç·¨é›†è€…ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
å¯¾è©±å½¢å¼ã§è¨˜äº‹ã‚’ãƒ–ãƒ©ãƒƒã‚·ãƒ¥ã‚¢ãƒƒãƒ—
"""
import os
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
from prompts import get_system_prompt

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="è¨˜äº‹æ”¹å–„ - YAE",
    page_icon="âœï¸",
    layout="wide"
)

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
@st.cache_resource
def get_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("âš ï¸ OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    return OpenAI(api_key=api_key)

client = get_openai_client()


# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "survey_data" not in st.session_state:
    st.session_state.survey_data = ""

if "generated_article" not in st.session_state:
    st.session_state.generated_article = ""

if "article_data" not in st.session_state:
    st.session_state.article_data = {}

if "evaluation_result" not in st.session_state:
    st.session_state.evaluation_result = {}

if "improvement_messages" not in st.session_state:
    st.session_state.improvement_messages = []

if "current_article" not in st.session_state:
    st.session_state.current_article = st.session_state.generated_article


# ãƒ˜ãƒƒãƒ€ãƒ¼
st.title("âœï¸ è¨˜äº‹æ”¹å–„")
st.caption("AIç·¨é›†è€…ã¨å¯¾è©±ã—ãªãŒã‚‰è¨˜äº‹ã‚’ãƒ–ãƒ©ãƒƒã‚·ãƒ¥ã‚¢ãƒƒãƒ—ã—ã¾ã™")

# ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
col1, col2, col3 = st.columns([1, 1, 1])
with col1:
    if st.button("â† è¨˜äº‹è©•ä¾¡ã¸æˆ»ã‚‹"):
        st.switch_page("pages/2_â­_è¨˜äº‹è©•ä¾¡.py")
with col2:
    if st.button("ğŸ  ãƒ›ãƒ¼ãƒ ã¸"):
        st.switch_page("app.py")

st.markdown("---")

# è¨˜äº‹ãŒæœªç”Ÿæˆã®å ´åˆ - ç›´æ¥å…¥åŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æä¾›
if not st.session_state.generated_article:
    st.info("ğŸ’¡ è¨˜äº‹ç”Ÿæˆãƒ»è©•ä¾¡ãƒšãƒ¼ã‚¸ã‹ã‚‰æ¥ã‚‹ã‹ã€ã¾ãŸã¯æ—¢å­˜ã®è¨˜äº‹ã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘ã¦æ”¹å–„ã§ãã¾ã™")

    col_a, col_b, col_c = st.columns(3)

    with col_a:
        if st.button("ğŸ“ è¨˜äº‹ç”Ÿæˆã¸ â†’", use_container_width=True):
            st.switch_page("pages/1_ğŸ“_è¨˜äº‹ç”Ÿæˆ.py")

    with col_b:
        if st.button("â­ è¨˜äº‹è©•ä¾¡ã¸ â†’", use_container_width=True):
            st.switch_page("pages/2_â­_è¨˜äº‹è©•ä¾¡.py")

    with col_c:
        show_input = st.button("âœï¸ è¨˜äº‹ã‚’ç›´æ¥å…¥åŠ›", use_container_width=True)

    if show_input or "show_improvement_input" in st.session_state:
        st.session_state.show_improvement_input = True

        st.markdown("---")
        st.subheader("ğŸ“ è¨˜äº‹ã®å…¥åŠ›")

        # è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«å…¥åŠ›
        article_title_input = st.text_input(
            "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«",
            value=st.session_state.article_data.get('title_candidates', [''])[0] if st.session_state.article_data else "",
            placeholder="ä¾‹: é«˜æ ¡ç”Ÿã®7å‰²ãŒInstagramã‚’åˆ©ç”¨"
        )

        # è¨˜äº‹æœ¬æ–‡å…¥åŠ›
        article_input = st.text_area(
            "è¨˜äº‹æœ¬æ–‡ï¼ˆMarkdownå½¢å¼ï¼‰",
            value=st.session_state.generated_article,
            height=400,
            placeholder="## ã¯ã˜ã‚ã«\n\né«˜æ ¡ç”Ÿã®ç´„7å‰²ãŒInstagramã‚’åˆ©ç”¨ã—...\n\n## çµæœ\n\n...",
            help="æ”¹å–„ã—ãŸã„è¨˜äº‹ã®æœ¬æ–‡ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„"
        )

        if st.button("ğŸ’¾ ä¿å­˜ã—ã¦æ”¹å–„ã‚’é–‹å§‹", type="primary", use_container_width=True):
            if article_input:
                st.session_state.generated_article = article_input
                st.session_state.current_article = article_input
                st.session_state.article_data = {
                    "title_candidates": [article_title_input] if article_title_input else ["ç„¡é¡Œ"],
                    "article_body": article_input
                }
                st.session_state.show_improvement_input = False
                st.success("âœ… è¨˜äº‹ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ãƒãƒ£ãƒƒãƒˆã§æ”¹å–„ã‚’å§‹ã‚ã¾ã—ã‚‡ã†ã€‚")
                st.rerun()
            else:
                st.warning("âš ï¸ è¨˜äº‹æœ¬æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    if not st.session_state.generated_article:
        st.stop()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šç¾åœ¨ã®è¨˜äº‹ã¨è©•ä¾¡çµæœ
with st.sidebar:
    st.title("ğŸ“„ ç¾åœ¨ã®è¨˜äº‹")

    # ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
    if st.session_state.article_data and "title_candidates" in st.session_state.article_data:
        st.markdown(f"### {st.session_state.article_data['title_candidates'][0]}")

    st.markdown("---")

    # è¨˜äº‹æœ¬æ–‡ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    st.subheader("è¨˜äº‹æœ¬æ–‡")
    with st.expander("å…¨æ–‡ã‚’è¡¨ç¤º", expanded=False):
        st.markdown(st.session_state.current_article)

    st.markdown("---")

    # è©•ä¾¡çµæœã®ã‚µãƒãƒªãƒ¼
    if st.session_state.evaluation_result:
        st.subheader("â­ è©•ä¾¡ã‚µãƒãƒªãƒ¼")

        if "total_score" in st.session_state.evaluation_result:
            st.metric("ç·åˆã‚¹ã‚³ã‚¢", f"{st.session_state.evaluation_result['total_score']}/40")

        if "summary" in st.session_state.evaluation_result:
            summary = st.session_state.evaluation_result["summary"]

            if "weaknesses" in summary and summary["weaknesses"]:
                st.markdown("**ä¸»ãªæ”¹å–„ç‚¹:**")
                for weakness in summary["weaknesses"][:3]:
                    st.warning(f"â€¢ {weakness}")

    st.markdown("---")

    # ãƒãƒ£ãƒƒãƒˆãƒªã‚»ãƒƒãƒˆ
    if st.button("ğŸ”„ ãƒãƒ£ãƒƒãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
        st.session_state.improvement_messages = []
        st.session_state.current_article = st.session_state.generated_article
        st.rerun()

    # è¨˜äº‹ã‚’ç·¨é›†
    if st.button("âœï¸ è¨˜äº‹ã‚’ç·¨é›†", use_container_width=True):
        st.session_state.show_improvement_input = True
        st.rerun()

    # è¨˜äº‹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.markdown("---")
    st.subheader("ğŸ’¾ è¨˜äº‹ã‚’ä¿å­˜")

    download_content = f"""# {st.session_state.article_data.get('title_candidates', ['è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«'])[0]}

{st.session_state.current_article}

---
ç”Ÿæˆæ—¥: {st.session_state.get('generation_date', 'N/A')}
YAE (Young AI Editor) ã§ç”Ÿæˆ
"""

    st.download_button(
        label="ğŸ“¥ Markdownå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=download_content,
        file_name="article.md",
        mime="text/markdown",
        use_container_width=True
    )


# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ï¼šãƒãƒ£ãƒƒãƒˆç”»é¢
st.subheader("ğŸ’¬ AIç·¨é›†è€…ã¨ãƒãƒ£ãƒƒãƒˆ")

# åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
if len(st.session_state.improvement_messages) == 0:
    with st.chat_message("assistant"):
        initial_message = """
ã“ã‚“ã«ã¡ã¯ï¼AIç·¨é›†è€…ã§ã™âœï¸

è¨˜äº‹ã®è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã“ã‚Œã‹ã‚‰å¯¾è©±ã‚’é€šã˜ã¦è¨˜äº‹ã‚’æ”¹å–„ã—ã¦ã„ãã¾ã—ã‚‡ã†ã€‚

**ã§ãã‚‹ã“ã¨:**
- æ–‡ä½“ã®èª¿æ•´ï¼ˆã€Œã‚‚ã£ã¨ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã«ã€ã€Œä¸å¯§ã«ã€ãªã©ï¼‰
- è¦‹å‡ºã—ã®å¤‰æ›´ãƒ»è¿½åŠ 
- è‡ªç”±å›ç­”ã®è¿½åŠ ãƒ»å‰Šé™¤
- æ§‹æˆã®å¤‰æ›´
- ç‰¹å®šã®è¡¨ç¾ã®ä¿®æ­£

**ä½¿ã„æ–¹ã®ä¾‹:**
- ã€Œã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚‚ã£ã¨ã‚­ãƒ£ãƒƒãƒãƒ¼ã«ã—ã¦ã€
- ã€Œè‡ªç”±å›ç­”ã‚’ã‚‚ã†2ã¤è¿½åŠ ã—ã¦ã€
- ã€Œç¬¬2æ®µè½ã‚’ã‚‚ã£ã¨ç°¡æ½”ã«ã—ã¦ã€
- ã€Œè¦‹å‡ºã—ã‚’3ã¤ã«åˆ†ã‘ã¦ã€

ä½•ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã‹ï¼Ÿ
"""
        st.markdown(initial_message)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
for message in st.session_state.improvement_messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt := st.chat_input("æ”¹å–„ã®æŒ‡ç¤ºã‚’å…¥åŠ›ï¼ˆä¾‹: ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚‚ã£ã¨ã‚­ãƒ£ãƒƒãƒãƒ¼ã«ã—ã¦ï¼‰"):

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    st.session_state.improvement_messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    # AIç·¨é›†è€…ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
        context_message = f"""
ã€å‚è€ƒæƒ…å ±ã€‘

ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿:
{st.session_state.survey_data}

ç¾åœ¨ã®è¨˜äº‹:
{st.session_state.current_article}

è©•ä¾¡çµæœ:
{st.session_state.evaluation_result.get('summary', {})}
"""

        # OpenAI APIã‚’å‘¼ã³å‡ºã—
        try:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
            messages = [
                {"role": "system", "content": get_system_prompt()}
            ]

            # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
            if len(st.session_state.improvement_messages) == 1:
                messages.append({
                    "role": "user",
                    "content": context_message + "\n\n" + prompt
                })
            else:
                # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¿½åŠ 
                for msg in st.session_state.improvement_messages:
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—
            message_placeholder.markdown("ğŸ’­ è€ƒãˆä¸­...")

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7,
                stream=False
            )

            full_response = response.choices[0].message.content
            message_placeholder.markdown(full_response)

            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
            st.session_state.improvement_messages.append({
                "role": "assistant",
                "content": full_response
            })

            # è¨˜äº‹ãŒæ›´æ–°ã•ã‚ŒãŸå ´åˆã¯ current_article ã‚’æ›´æ–°
            # (å®Ÿéš›ã«ã¯ã€AIã®å›ç­”ã‹ã‚‰è¨˜äº‹éƒ¨åˆ†ã‚’æŠ½å‡ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ãŒã€
            #  ã“ã“ã§ã¯ç°¡æ˜“çš„ã«å…¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¨˜éŒ²)

        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


# ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
st.markdown("---")
st.info("""
ğŸ’¡ **ãƒ’ãƒ³ãƒˆ:**
- å…·ä½“çš„ãªæŒ‡ç¤ºã‚’å‡ºã™ã»ã©ã€çš„ç¢ºãªä¿®æ­£ãŒå¾—ã‚‰ã‚Œã¾ã™
- ã€Œè¦‹å‡ºã—ã‚’å¤‰ãˆã¦ã€ã§ã¯ãªãã€Œè¦‹å‡ºã—ã‚’ã‚‚ã£ã¨ã‚ã‹ã‚Šã‚„ã™ãã€10ä»£ã«åˆºã•ã‚‹è¡¨ç¾ã«ã—ã¦ã€
- ä¿®æ­£å¾Œã®è¨˜äº‹ã¯å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™
""")
